#!python -u
"""
This module reads an input file containing nogoods and generates the patterns
Afterwards, the patterns are clustered and facts are generated for them
and printed in the output file.
Classes:
Literal
Pattern
Nogood
"""

import csv
from Nogood import *
import time
from pattern_functions import *
from get_path import *
import os
import subprocess
#from Globals import *
from Fact import *
import time
from fact_ConAcq import *
import sys
if eval_flag:
    expression_re = re.compile(r"[1-9][0-9]*[-+*-][1-9][0-9]*")
#def main(in1, in2, in3):

def main():
    # mzn_model_name = sys.argv[1]
    # data_file_name = sys.argv[2]
    # direct = sys.argv[3]
    # global mzn_model_name
    # mzn_model_name = in1
    # data_file_name = in2
    # direct = in3
    nogoods = []  # list of nogood classes
    patterns = []  # all the patterns
    patterns_wo_nogoods = []  # patterns without the ones generated by a single pattern
    start_time = time.time()
    ofile = open(ofile_result_dir, "wb")  # this file contains the patterns
    ofile_model_with_pattern = open(ifile_model_with_pattern_dir, "wb")  # this file contains the model with the pattern
    ofile_solutions_for_model_with_pattern = open(ofile_solutions_for_model_with_pattern_dir, "wb")  # this file stores the solutions
    # of the model with pattern
    #ofile_solutions_for_model_with_pattern_after_counting = open(ofile_solutions_for_model_with_pattern_after_counting_dir, "wb")
    ofile_test = open(ofile_test_dir, "wb")
    ifile_original_model = open(ifile_original_model_dir, "rb")
    original_model_str = ifile_original_model.read()
    csv.writer(ofile, delimiter=delimiter)
    ctr = 0
    num_nogoods = 0
    sum_len_nogoods = 0
    """
    Read the nogoods from the file
    """
    with open(ifile_nogood, 'r') as f:
        reader = csv.reader(f, delimiter='\t')
        reader.next()
        for row in reader:
            ctr += 1
            if num_nogoods == 50:  # only reads the first 1000 nogoods
                break
            nogood_ID = row[0]
            if nogood_ID == "":  # in case that input file contains empty lines
                break
            seq_lits = []
            nogood_name = row[8]

            nogood_name = nogood_name.replace("'", "")
            nogood_name = nogood_name.replace("=true", "")
            #if "sum" in nogood_name or "unknown" or "XI:" in nogood_name:
            #    continue
            if eval_flag:  # if there are expressions in the nogoods, they would be evaluated
                # e.g. a[1+4] => a[5]
                expressions = expression_re.findall(nogood_name)  # finds all the expressions in the nogood
                # such as 1+2, 3-4, ..
                for exp in expressions:
                    nogood_name = nogood_name.replace(exp, str(eval(exp)))  # replaces the expressions
                    # with their evaluations

            for lit_str in nogood_name.split():  # creates an object of Literal for each literal in the nogood
                lit = Literal(lit_str)  # generates a Literal object for each literal

                lit.update()  # updates some of the literals attributes that are fixed (to avoid using copy.deepcopy)
                seq_lits.append(lit)

            num_nogoods += 1
            sum_len_nogoods += len(seq_lits)

            red = int(row[7])  # reads the reduction in search space
            # if red < 20:
            #     continue
            paths = get_path(row[9])  # returns all the paths corresponding to the nogood
            nogoods.append(Nogood(nogood_ID, seq_lits, red, paths))   # convert nogood strings to objects with the
            # sorted literals

    ofile_statistics = open(ofile_statistics_dir, "wb")
    if num_nogoods != 0:
        avg_nogood_length = float(sum_len_nogoods)/float(num_nogoods)
    else:
        avg_nogood_length = 0
    #print "Num nogoods: %s" %(time.time() - start_time)
    #ofile_statistics.write("Num nogoods: %s" %(time.time() - start_time))
    ofile_statistics.write("Num nogoods: %s" %(num_nogoods) + "\n")
    ofile_statistics.write("Avg nogood length: %s" %(avg_nogood_length) + "\n")
    time_nogood = time.time()
    print("--- %s seconds ---" % (time.time() - start_time))
    for nogood in nogoods:
        """
        get the attributes of nogood
        """

        p1_seq_lits = nogood.get_seq_lits()
        p1_num_lits = len(p1_seq_lits)
        p1_id = nogood.get_ID()
        p1_red = nogood.get_red()
        p1_paths = nogood.get_paths()
        p1 = Pattern([p1_id], p1_seq_lits, [], [p1_red], [p1_paths])  # add nogood as a new pattern
        p1_variable_names = p1.get_variable_names()
        p1_ops = p1.get_operators()
        patterns.append(p1)  # add p1 (generated from nogood) as a new pattern
        for p in range(0, len(patterns)-1):  # compare the nogood to all the patterns except itself(len(patterns)-1)
            p2_seq_lits = patterns[p].get_seq_lits()
            p2_num_lits = len(p2_seq_lits)
            p2_ops = patterns[p].get_operators()
            p2_variable_names = patterns[p].get_variable_names()
            if (p1_num_lits == p2_num_lits and p1_ops == p2_ops
                and p2_variable_names == p1_variable_names):  # if patterns[p] and nogood have
                #  the same operators, number of literals and variables
                try:
                    new_p = generate_pattern(patterns[p], nogood)
                except:
                    print "can't generate pattern"
                    # print patterns[p]
                    # print nogood
                    # print p1_id
                    # print patterns[p].get_maps()
                ind = pattern_exists(patterns_wo_nogoods, new_p)  # checks if a renaming or the same pattern as
                if ind > -1:  # if there is an existing pattern, adds all the nogoods under the new_p to the pattern
                    ng_ids = new_p.get_IDS()
                    maps = new_p.get_maps()
                    new_p_nums = new_p.get_pnums()
                    reductions = new_p.get_reds()
                    consts = new_p.get_paths()
                    ng_ids_old = patterns_wo_nogoods[ind].get_IDS()  # nogood ids under the existing pattern
                    for n in range(0, len(maps)):
                        if ng_ids[n] not in ng_ids_old:  # to not add the same nogood to the patterns[ind]
                            patterns_wo_nogoods[ind].add_map([ng_ids[n]], [new_p_nums[n]],
                                                             [reductions[n]],
                                                             [consts[n]])  # add the maps corresponding
                else:
                    patterns.append(new_p)  # if new_p doesnt exist it would be added to the patterns
                    patterns_wo_nogoods.append(new_p)

    time_after_pattern = time.time() - time_nogood
    ofile_statistics.write("Time to generate pattern: %s" %time_after_pattern + "\n")
    print("Patterns generated")
    print("--- %s seconds ---" % (time.time() - start_time))
    patterns.sort(key=attrgetter('sum_reduction'))  # sort the patterns based on sum_reduction
    patterns = patterns[::-1]  # from largest sum_reduction to the smallest
    write_str = "Name" + delimiter + "Total Reduction" + delimiter + "Length of Nogood" + delimiter + "Num associated parameter" + delimiter + "Num Objects" + delimiter + "Num nogoods" + delimiter + "Fact CONACQ" + delimiter + "Max Fact Nogood" + delimiter + "Reduction per Cluster" + delimiter + "Maps" + delimiter + "Paths\n"
    ctr = 0
    time_facts = 0
    time_facts_conacq = 0
    avg_obj = 0
    avg_param = 0
    for p in patterns:
        #if ctr < 3: # just for testing
        if True:
            # print p
            # print p.negate_pattern_all_enum()
            # print ""
            ctr += 1
            cluster_str = get_cluster_str(p, delimiter)
            time_before_fact = time.time()
            f = Fact(p)
            time_each_fact = time.time() - time_before_fact
            time_facts += time_each_fact
            #types = p.get_var_types_no_rep()
            fact_CONACQ_str = ""
            # for t in types:
            #     CONACQ_res_for_t = str(add_negated_pattern_to_the_model(p, t))
            #     if CONACQ_res_for_t:
            #         fact_CONACQ_str += str(t) + ":" + CONACQ_res_for_t + " "
            write_str += p.get_name() + delimiter
            write_str += str(p.get_sum_reduction()) + delimiter
            length_clause = len(p.get_name().split())
            write_str += str(length_clause) + delimiter
            # Calculate numbers of objects and parameters associated to the each pattern
            all_objects_of_same_type = p.get_all_objects_of_the_same_type()
            parameters_indexed_by_objects = p.get_parameters_indexed_by_objects()

            each_length_obj = [len(lst) for lst in all_objects_of_same_type]
            sum_obj = 0
            for each in each_length_obj:
                sum_obj += each
            each_length_param = [len(lst) for lst in parameters_indexed_by_objects]
            sum_param = 0
            for each in each_length_param:
                sum_param += each
            total_number_obj = len(all_objects_of_same_type)
            total_number_param = len(parameters_indexed_by_objects)
            avg_obj += float(sum_obj)/float(total_number_obj)
            avg_param += float(sum_param)/float(total_number_param)
            #print str(each_length_param) + ", " + str(len(parameters_indexed_by_objects))
            num_parameters = 0
            for param in parameters_indexed_by_objects:
                if len(param) != 0:
                    num_parameters += 1
            num_objects = 0
            for objs in all_objects_of_same_type:
                num_objects += len(objs)
            write_str += str(num_parameters) + delimiter
            write_str += str(num_objects) + delimiter
            num_nogoods = len(p.get_maps())
            write_str += str(num_nogoods) + delimiter
            if "objective" and "(" and "XI:" and "ofvar" and "builtins.mzn" not in p.get_name():
                time_before_fact_conacq = time.time()
                write_str += calculate_all_facts_CONACQ_vars(p) + delimiter
                #write_str += " " + delimiter
                time_each_fact_conacq = time.time() - time_before_fact_conacq
                time_facts_conacq += time_each_fact_conacq
            else:
                write_str += " " + delimiter
            # if fact_CONACQ_str != 0:
            #     write_str += str(fact_CONACQ_str)
            #write_str += delimiter
            write_str += f.get_fact_str()
            write_str += cluster_str + delimiter
            write_str += '\n'
            ofile_test.write("pattern name:\n")
            ofile_test.writelines(p.get_name())
            ofile_test.write("\n")
            ofile_test.write("Vouchers:\n")
            #ofile_test.write(str(p.get_params_for_a_type("VOUCHER")))
            ofile_test.write("\n")
            ofile_test.write("pizzas\n")
            #ofile_test.write(str(p.get_params_for_a_type("PIZZA")))
            ofile_test.write("\n")
            ofile_test.write("\n")
            ofile_test.write("\n")
    ofile.write(write_str)
    ofile.close()
    if len(patterns) != 0:
        avg_obj_allp = float(avg_obj)/float(len(patterns))
        avg_param_allp = float(avg_param)/float(len(patterns))
    else:
        avg_obj_allp = 0
        avg_param_allp = 0
    ofile_statistics.write("Num obj: " + str(avg_obj_allp) + "\n")
    ofile_statistics.write("Num param: " + str(avg_param_allp) + "\n")

    ofile_statistics.write("Time to generate facts Method 1: " + str(time_facts) + "\n")
    ofile_statistics.write("Time to generate facts Method 2: " + str(time_facts_conacq) + "\n")
    ofile_statistics.write("Total time: " + str(time.time() - start_time) + "\n")
    print ("Finished")
    print("--- %s seconds ---" % (time.time() - start_time))
if __name__ == '__main__':
    from pyinstrument import Profiler
    profiler = Profiler()
    profiler.start()
    main()
    profiler.stop()
    print(profiler.output_text(unicode=True, color=True))
